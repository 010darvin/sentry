# Generated by Django 2.2.28 on 2022-09-14 05:11
import os

from django.conf import settings
from django.db import connections, migrations

from sentry.new_migrations.migrations import CheckedMigration
from sentry.silo import SiloMode


def tables(apps):
    tables = [
        model_class._meta.db_table
        for model_class in apps.get_models()
        if model_class._meta.app_label == "sentry"
        and list(model_class._meta._ModelSiloLimit__silo_limit.modes)[0] == SiloMode.CONTROL
    ]
    return tables


def create_db(apps, schema_editor):
    with connections["default"].cursor() as cursor:
        cursor.execute("CREATE DATABASE control_silo")


# We only export the schema so that we can maintain optionality about shelling out to pg_dump
# If we decide not to do that, we could just inline the output of pgdump at a point in time
def create_and_import_pg_dump(apps, schema_editor):
    c = connections["default"].settings_dict
    with connections["control_silo"].cursor() as control_cursor:
        control_cursor.execute("CREATE EXTENSION IF NOT EXISTS citext")
        table_flags = " ".join([f"-t {table} " for table in tables(apps)])
        cmd = f"pg_dump -U {c['USER']} -h {c['HOST']} {c['NAME']} {table_flags} --schema-only > /tmp/control_tables.sql"
        os.system(cmd)
        # Read file and run contents:
        with open("/tmp/control_tables.sql") as file:
            sql = file.read()
            control_cursor.execute(sql)


def move_table_data(apps, schema_editor):
    with connections["default"].cursor() as default_cursor:
        with connections["control_silo"].cursor() as control_cursor:
            for table in tables(apps):
                sql = f"COPY {table} TO '/tmp/{table}.csv' csv header"
                default_cursor.execute(sql)

                sql = f"COPY public.{table} FROM '/tmp/{table}.csv' csv header "
                control_cursor.execute(sql)


class Migration(CheckedMigration):
    # This flag is used to mark that a migration shouldn't be automatically run in production. For
    # the most part, this should only be used for operations where it's safe to run the migration
    # after your code has deployed. So this should not be used for most operations that alter the
    # schema of a table.
    # Here are some things that make sense to mark as dangerous:
    # - Large data migrations. Typically we want these to be run manually by ops so that they can
    #   be monitored and not block the deploy for a long period of time while they run.
    # - Adding indexes to large tables. Since this can take a long time, we'd generally prefer to
    #   have ops run this and not block the deploy. Note that while adding an index is a schema
    #   change, it's completely safe to run the operation after the code has deployed.
    is_dangerous = False

    # This flag is used to decide whether to run this migration in a transaction or not. Generally
    # we don't want to run in a transaction here, since for long running operations like data
    # back-fills this results in us locking an increasing number of rows until we finally commit.
    atomic = False

    dependencies = [
        ("sentry", "0315_add_type_to_group"),
    ]

    # TODO: Figure out how to make this only run in dev

    operations = []
    if settings.IS_DEV:
        operations = [
            # No hints means use the default DB
            migrations.RunPython(
                create_db,
            ),
            migrations.RunPython(
                create_and_import_pg_dump,
            ),
            migrations.RunPython(
                move_table_data,
                hints={"tables": tables},  # Run on control silo
            ),
        ]
